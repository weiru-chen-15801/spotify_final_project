{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_features = []\n",
    "for i in range(100):\n",
    "    file = pd.read_csv(\"Spotify_API/dfs_first_100_playlists_features/df_playlist_features_\"+str(i)+\".csv\")\n",
    "    raw_features.append(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last.fm tags into response labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#unique tags threshold\n",
    "threshold = 3000\n",
    "#threshold = 1000\n",
    "unique_tags = []\n",
    "with open(\"last.fm/lastfm_unique_tags.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        tag_freq = line.split('\\t')\n",
    "        if int(tag_freq[1]) > threshold:\n",
    "            unique_tags.append(tag_freq[0])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create all zero value dictionary\n",
    "\n",
    "def get_zero_dict():\n",
    "    zeros_dict = {}\n",
    "    for tag in unique_tags:\n",
    "        zeros_dict.update({tag: 0.0})\n",
    "    return zeros_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the mean value of features of all the songs in the playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>energy</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>...</th>\n",
       "      <th>World Music</th>\n",
       "      <th>genius</th>\n",
       "      <th>noise</th>\n",
       "      <th>saxophone</th>\n",
       "      <th>Favorite Artists</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>feelgood</th>\n",
       "      <th>new</th>\n",
       "      <th>folk-rock</th>\n",
       "      <th>pretty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.663922</td>\n",
       "      <td>0.107875</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.192404</td>\n",
       "      <td>0.779078</td>\n",
       "      <td>0.645608</td>\n",
       "      <td>222076.627451</td>\n",
       "      <td>5.117647</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.001731</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166732</td>\n",
       "      <td>0.493655</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.174761</td>\n",
       "      <td>0.686868</td>\n",
       "      <td>0.472711</td>\n",
       "      <td>299176.157895</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273359</td>\n",
       "      <td>0.671952</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>0.690095</td>\n",
       "      <td>0.565460</td>\n",
       "      <td>219076.174603</td>\n",
       "      <td>4.984127</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266913</td>\n",
       "      <td>0.509253</td>\n",
       "      <td>0.066359</td>\n",
       "      <td>0.210820</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>0.624924</td>\n",
       "      <td>0.460534</td>\n",
       "      <td>229373.898990</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181532</td>\n",
       "      <td>0.582188</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>0.086992</td>\n",
       "      <td>0.169556</td>\n",
       "      <td>0.636631</td>\n",
       "      <td>0.489375</td>\n",
       "      <td>256603.562500</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  speechiness  instrumentalness  liveness  \\\n",
       "0      0.085044      0.663922     0.107875          0.000689  0.192404   \n",
       "1      0.166732      0.493655     0.089239          0.228118  0.174761   \n",
       "2      0.273359      0.671952     0.096359          0.000648  0.170416   \n",
       "3      0.266913      0.509253     0.066359          0.210820  0.197497   \n",
       "4      0.181532      0.582188     0.041513          0.086992  0.169556   \n",
       "\n",
       "     energy   valence    duration_ms       key      mode  ...  World Music  \\\n",
       "0  0.779078  0.645608  222076.627451  5.117647  0.705882  ...     0.001154   \n",
       "1  0.686868  0.472711  299176.157895  4.578947  0.552632  ...     0.000000   \n",
       "2  0.690095  0.565460  219076.174603  4.984127  0.507937  ...     0.000000   \n",
       "3  0.624924  0.460534  229373.898990  5.090909  0.707071  ...     0.000000   \n",
       "4  0.636631  0.489375  256603.562500  3.187500  0.812500  ...     0.000000   \n",
       "\n",
       "     genius   noise  saxophone  Favorite Artists  indietronica  feelgood  \\\n",
       "0  0.000385  0.0000        0.0          0.000962        0.0000  0.001731   \n",
       "1  0.000000  0.0000        0.0          0.000000        0.0000  0.000000   \n",
       "2  0.000000  0.0000        0.0          0.000000        0.0000  0.000000   \n",
       "3  0.000200  0.0075        0.0          0.002800        0.0165  0.001400   \n",
       "4  0.000000  0.0000        0.0          0.000000        0.0000  0.000000   \n",
       "\n",
       "        new  folk-rock    pretty  \n",
       "0  0.001346        0.0  0.000577  \n",
       "1  0.000256        0.0  0.000000  \n",
       "2  0.000000        0.0  0.007812  \n",
       "3  0.000200        0.0  0.001700  \n",
       "4  0.000000        0.0  0.000000  \n",
       "\n",
       "[5 rows x 287 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = list(raw_features[0].columns)[4:]\n",
    "#print(feature_names)\n",
    "\n",
    "labels = []\n",
    "with open('labels_100_playlists.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    label_columns = list(data[0].keys())\n",
    "    for item in data:\n",
    "        #label = list(item.values())\n",
    "        #label = np.array(label)*100\n",
    "        #labels.append(list(label))\n",
    "        labels.append(list(item.values()))\n",
    "    \n",
    "features = []\n",
    "for raw_playlist in raw_features:\n",
    "    raw_playlist = raw_playlist.drop(columns=['track_name', 'artist', 'id','Unnamed: 0'])\n",
    "    new_feature_array_playlist = list(raw_playlist.mean())\n",
    "    features.append(new_feature_array_playlist)\n",
    "\n",
    "overall_data = []\n",
    "for i in range(len(features)):\n",
    "    overall_data.append(features[i]+labels[i])\n",
    "\n",
    "overall_df = pd.DataFrame(overall_data, columns = feature_names+label_columns)\n",
    "overall_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When find top n labels and label them with 1 (others 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>energy</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>...</th>\n",
       "      <th>World Music</th>\n",
       "      <th>genius</th>\n",
       "      <th>noise</th>\n",
       "      <th>saxophone</th>\n",
       "      <th>Favorite Artists</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>feelgood</th>\n",
       "      <th>new</th>\n",
       "      <th>folk-rock</th>\n",
       "      <th>pretty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.663922</td>\n",
       "      <td>0.107875</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.192404</td>\n",
       "      <td>0.779078</td>\n",
       "      <td>0.645608</td>\n",
       "      <td>222076.627451</td>\n",
       "      <td>5.117647</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166732</td>\n",
       "      <td>0.493655</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.174761</td>\n",
       "      <td>0.686868</td>\n",
       "      <td>0.472711</td>\n",
       "      <td>299176.157895</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273359</td>\n",
       "      <td>0.671952</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>0.690095</td>\n",
       "      <td>0.565460</td>\n",
       "      <td>219076.174603</td>\n",
       "      <td>4.984127</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266913</td>\n",
       "      <td>0.509253</td>\n",
       "      <td>0.066359</td>\n",
       "      <td>0.210820</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>0.624924</td>\n",
       "      <td>0.460534</td>\n",
       "      <td>229373.898990</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181532</td>\n",
       "      <td>0.582188</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>0.086992</td>\n",
       "      <td>0.169556</td>\n",
       "      <td>0.636631</td>\n",
       "      <td>0.489375</td>\n",
       "      <td>256603.562500</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  speechiness  instrumentalness  liveness  \\\n",
       "0      0.085044      0.663922     0.107875          0.000689  0.192404   \n",
       "1      0.166732      0.493655     0.089239          0.228118  0.174761   \n",
       "2      0.273359      0.671952     0.096359          0.000648  0.170416   \n",
       "3      0.266913      0.509253     0.066359          0.210820  0.197497   \n",
       "4      0.181532      0.582188     0.041513          0.086992  0.169556   \n",
       "\n",
       "     energy   valence    duration_ms       key      mode  ...  World Music  \\\n",
       "0  0.779078  0.645608  222076.627451  5.117647  0.705882  ...            0   \n",
       "1  0.686868  0.472711  299176.157895  4.578947  0.552632  ...            0   \n",
       "2  0.690095  0.565460  219076.174603  4.984127  0.507937  ...            0   \n",
       "3  0.624924  0.460534  229373.898990  5.090909  0.707071  ...            0   \n",
       "4  0.636631  0.489375  256603.562500  3.187500  0.812500  ...            0   \n",
       "\n",
       "   genius  noise  saxophone  Favorite Artists  indietronica  feelgood  new  \\\n",
       "0       0      0          0                 0             0         0    0   \n",
       "1       0      0          0                 0             0         0    0   \n",
       "2       0      0          0                 0             0         0    0   \n",
       "3       0      0          0                 0             0         0    0   \n",
       "4       0      0          0                 0             0         0    0   \n",
       "\n",
       "   folk-rock  pretty  \n",
       "0          0       0  \n",
       "1          0       0  \n",
       "2          0       1  \n",
       "3          0       0  \n",
       "4          0       0  \n",
       "\n",
       "[5 rows x 287 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = list(raw_features[0].columns)[4:]\n",
    "#print(feature_names)\n",
    "\n",
    "top_n_tags = 20\n",
    "\n",
    "labels = []\n",
    "with open('labels_100_playlists.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    label_columns = list(data[0].keys())\n",
    "    for item in data:\n",
    "        label = list(item.values())\n",
    "        sorted_label_top_n = sorted(label, reverse=True)[0:top_n_tags]\n",
    "        new_label = [0]*len(label)\n",
    "        for num in sorted_label_top_n:\n",
    "            new_label[label.index(num)] = 1\n",
    "        \n",
    "        labels.append(new_label)\n",
    "        #labels.append(list(item.values()))\n",
    "    \n",
    "features = []\n",
    "for raw_playlist in raw_features:\n",
    "    raw_playlist = raw_playlist.drop(columns=['track_name', 'artist', 'id','Unnamed: 0'])\n",
    "    new_feature_array_playlist = list(raw_playlist.mean())\n",
    "    features.append(new_feature_array_playlist)\n",
    "\n",
    "overall_data = []\n",
    "for i in range(len(features)):\n",
    "    overall_data.append(features[i]+labels[i])\n",
    "\n",
    "overall_df = pd.DataFrame(overall_data, columns = feature_names+label_columns)\n",
    "overall_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#standardize (normalize X_df)\n",
    "X_df = overall_df[feature_names]\n",
    "X_df=(X_df-X_df.mean())/X_df.std()\n",
    "y_df = overall_df[label_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/weiruchen/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Training Accuracy: 5.00\n",
      "Test Accuracy: 15.00\n"
     ]
    }
   ],
   "source": [
    "# ouput activation: linear\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, input_dim=13, activation='relu'),\n",
    "  tf.keras.layers.Dense(40, input_dim = 20, activation = 'linear'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(274, activation='linear')\n",
    "])\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=20, verbose=0)\n",
    "\n",
    "_,train_accuracy = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Training Accuracy: %.2f' % (train_accuracy*100))\n",
    "\n",
    "_,test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.2f' % (test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/weiruchen/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Training Accuracy: 97.57\n",
      "Test Accuracy: 94.42\n"
     ]
    }
   ],
   "source": [
    "# ouput activation: sigmoid\n",
    "model_sigmoid_with_linear = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, input_dim=13, activation='relu'),\n",
    "  tf.keras.layers.Dense(40, input_dim = 20, activation = 'linear'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(274, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the keras model\n",
    "model_sigmoid_with_linear.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_sigmoid_with_linear.fit(X_train, y_train, epochs=300, batch_size=20, verbose=0)\n",
    "\n",
    "_,train_accuracy = model_sigmoid_with_linear.evaluate(X_train, y_train, verbose=0)\n",
    "print('Training Accuracy: %.2f' % (train_accuracy*100))\n",
    "\n",
    "_,test_accuracy = model_sigmoid_with_linear.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.2f' % (test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.6373187e-01, 9.9847394e-01, 6.1939943e-01, ..., 1.8805265e-05,\n",
       "        1.6421080e-05, 1.4381397e-01],\n",
       "       [4.1042763e-01, 9.9997324e-01, 8.4382403e-01, ..., 2.0861626e-07,\n",
       "        2.0861626e-07, 2.8580487e-02],\n",
       "       [6.3554579e-01, 6.9452047e-01, 1.8082467e-01, ..., 1.1920929e-07,\n",
       "        5.9604645e-08, 5.3256750e-05],\n",
       "       ...,\n",
       "       [8.4524202e-01, 9.9967837e-01, 9.7104192e-01, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 5.0663948e-07],\n",
       "       [9.3135953e-01, 6.1041820e-01, 1.5199488e-01, ..., 3.0100346e-06,\n",
       "        1.0818243e-05, 8.9406967e-08],\n",
       "       [9.3865430e-01, 1.8767163e-01, 9.6377248e-01, ..., 1.6808510e-05,\n",
       "        4.8279762e-06, 1.7881393e-07]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_sigmoid_with_linear = model_sigmoid_with_linear.predict(X_test)\n",
    "probs_sigmoid_with_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 96.69\n",
      "Test Accuracy: 95.07\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, input_dim=13, activation='relu'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(274, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the keras model\n",
    "model_sigmoid.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_sigmoid.fit(X_train, y_train, epochs=300, batch_size=20, verbose=0)\n",
    "\n",
    "_,train_accuracy = model_sigmoid.evaluate(X_train, y_train, verbose=0)\n",
    "print('Training Accuracy: %.2f' % (train_accuracy*100))\n",
    "\n",
    "_,test_accuracy = model_sigmoid.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Accuracy: %.2f' % (test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8428270e-01, 9.8033547e-01, 4.9242327e-01, ..., 1.7479062e-04,\n",
       "        1.6358495e-04, 1.3241139e-01],\n",
       "       [3.9406994e-01, 9.9942052e-01, 8.4513140e-01, ..., 5.3942204e-06,\n",
       "        6.6757202e-06, 5.3915590e-02],\n",
       "       [8.3960295e-01, 2.2968027e-01, 9.6230775e-02, ..., 1.7583370e-06,\n",
       "        2.2351742e-06, 1.6769767e-04],\n",
       "       ...,\n",
       "       [8.4513485e-01, 9.9672103e-01, 9.0637910e-01, ..., 8.9406967e-08,\n",
       "        3.5762787e-07, 8.2105398e-05],\n",
       "       [9.5967406e-01, 5.7292360e-01, 3.3851159e-01, ..., 4.1157007e-05,\n",
       "        1.8656254e-05, 7.4505806e-07],\n",
       "       [9.5869821e-01, 4.5909372e-01, 9.6265197e-01, ..., 1.6570091e-05,\n",
       "        2.5451183e-05, 4.1723251e-07]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sigmoid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 0s 468us/sample - loss: 0.5003 - acc: 0.0000e+00\n",
      "Training Accuracy: 0.00\n",
      "20/20 [==============================] - 0s 27us/sample - loss: 0.5003 - acc: 0.0000e+00\n",
      "Test Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# ouput activation: sigmoid (loss_function: mean absolute error)\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, input_dim=13, activation='relu'),\n",
    "  tf.keras.layers.Dense(40, input_dim = 20, activation = 'linear'),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(274, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(loss='mean_absolute_error', optimizer='adadelta', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=20, verbose=0)\n",
    "\n",
    "_,train_accuracy = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Training Accuracy: %.2f' % (train_accuracy*100))\n",
    "\n",
    "_,test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Accuracy: %.2f' % (test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41673705, 0.48534018, 0.54806006, ..., 0.5089556 , 0.46977597,\n",
       "        0.5506634 ],\n",
       "       [0.42541397, 0.46821764, 0.55730087, ..., 0.5031049 , 0.44335607,\n",
       "        0.54143   ],\n",
       "       [0.39183775, 0.4963807 , 0.58997333, ..., 0.49727148, 0.37965566,\n",
       "        0.6536895 ],\n",
       "       ...,\n",
       "       [0.45275742, 0.5119368 , 0.57730836, ..., 0.48390085, 0.38033125,\n",
       "        0.60264015],\n",
       "       [0.5580218 , 0.5372651 , 0.5812974 , ..., 0.47726208, 0.40879658,\n",
       "        0.64835674],\n",
       "       [0.51903504, 0.5270925 , 0.5086614 , ..., 0.4947985 , 0.4452473 ,\n",
       "        0.5590695 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN Model (Convoluted Neural Networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(66, 30, 13, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_features = []\n",
    "valid_data_indices = []\n",
    "for i in range(0, 100):\n",
    "    feature_sing = pd.read_csv(\"Spotify_API/dfs_first_100_playlists_features/df_playlist_features_\" + str(i) + \".csv\")\n",
    "    feature_sing = feature_sing.drop(columns=['track_name', 'artist', 'id','Unnamed: 0'])\n",
    "    feature_sing = feature_sing.dropna()\n",
    "    feature_sing = feature_sing.to_numpy()\n",
    "    num_songs = feature_sing.shape[0]\n",
    "    if (num_songs >= 30):\n",
    "        valid_data_indices.append(i)\n",
    "        playlist_features.append(feature_sing[:30, ].reshape((30, 13, 1)))\n",
    "playlist_features = np.array(playlist_features)\n",
    "print(len(valid_data_indices))\n",
    "playlist_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "playlist_features_mean = np.mean(playlist_features, axis=(0, 1), keepdims = True)\n",
    "playlist_features_std = np.std(playlist_features, axis=(0, 1), keepdims = True)\n",
    "playlist_features = (playlist_features - playlist_features_mean) / playlist_features_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in labels\n",
    "playlist_tags = []\n",
    "with open('labels_100_playlists.json') as json_file:\n",
    "    raw_label = json.load(json_file)\n",
    "    for i in range(len(raw_label)):\n",
    "        # filter labels with valid features\n",
    "        if i in valid_data_indices:\n",
    "            label = raw_label[i]\n",
    "            label = np.array(list(label.values()))\n",
    "            playlist_tags.append(label)\n",
    "\n",
    "    playlist_tags = np.array(playlist_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split get random indices\n",
    "import random\n",
    "from random import sample\n",
    "random.seed( 209 )\n",
    "test_indices = random.sample(range(0, 66), 7)\n",
    "\n",
    "# split features\n",
    "train_features = []\n",
    "test_features = []\n",
    "for i in range(len(playlist_features)):\n",
    "    if i in test_indices:\n",
    "        test_features.append(playlist_features[i])\n",
    "    else:\n",
    "        train_features.append(playlist_features[i])\n",
    "\n",
    "train_features = np.array(train_features)\n",
    "test_features = np.array(test_features)\n",
    "\n",
    "# split labels\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "for i in range(len(playlist_tags)):\n",
    "    if i in test_indices:\n",
    "        test_labels.append(playlist_tags[i])\n",
    "    else:\n",
    "        train_labels.append(playlist_tags[i])\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "input_shape = train_features[0].shape\n",
    "num_category = train_labels[0].shape[0]\n",
    "\n",
    "##model building\n",
    "cnn_model = models.Sequential()\n",
    "#convolutional layer with rectified linear unit activation\n",
    "cnn_model.add(layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "cnn_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "cnn_model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "cnn_model.add(layers.Dropout(0.25))\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "cnn_model.add(layers.Flatten())\n",
    "#fully connected to get all relevant data\n",
    "cnn_model.add(layers.Dense(128, activation='relu'))\n",
    "#one more dropout for convergence' sake :) \n",
    "cnn_model.add(layers.Dropout(0.2))\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "cnn_model.add(layers.Dense(num_category, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use adaDelta as the adaptive learning rate\n",
    "cnn_model.compile(loss=tf.keras.losses.binary_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59 samples, validate on 7 samples\n",
      "Epoch 1/30\n",
      "59/59 [==============================] - 0s 5ms/sample - loss: 0.6753 - acc: 0.2649 - val_loss: 0.5968 - val_acc: 0.3441\n",
      "Epoch 2/30\n",
      "59/59 [==============================] - 0s 656us/sample - loss: 0.5714 - acc: 0.3406 - val_loss: 0.4626 - val_acc: 0.3848\n",
      "Epoch 3/30\n",
      "59/59 [==============================] - 0s 680us/sample - loss: 0.4592 - acc: 0.3731 - val_loss: 0.3323 - val_acc: 0.4150\n",
      "Epoch 4/30\n",
      "59/59 [==============================] - 0s 607us/sample - loss: 0.3641 - acc: 0.4023 - val_loss: 0.2245 - val_acc: 0.4453\n",
      "Epoch 5/30\n",
      "59/59 [==============================] - 0s 618us/sample - loss: 0.2729 - acc: 0.4291 - val_loss: 0.1457 - val_acc: 0.4682\n",
      "Epoch 6/30\n",
      "59/59 [==============================] - 0s 647us/sample - loss: 0.2058 - acc: 0.4473 - val_loss: 0.0952 - val_acc: 0.4791\n",
      "Epoch 7/30\n",
      "59/59 [==============================] - 0s 670us/sample - loss: 0.1437 - acc: 0.4651 - val_loss: 0.0668 - val_acc: 0.4891\n",
      "Epoch 8/30\n",
      "59/59 [==============================] - 0s 663us/sample - loss: 0.1150 - acc: 0.4727 - val_loss: 0.0537 - val_acc: 0.4896\n",
      "Epoch 9/30\n",
      "59/59 [==============================] - 0s 669us/sample - loss: 0.0922 - acc: 0.4788 - val_loss: 0.0481 - val_acc: 0.4896\n",
      "Epoch 10/30\n",
      "59/59 [==============================] - 0s 663us/sample - loss: 0.0749 - acc: 0.4830 - val_loss: 0.0456 - val_acc: 0.4896\n",
      "Epoch 11/30\n",
      "59/59 [==============================] - 0s 667us/sample - loss: 0.0701 - acc: 0.4839 - val_loss: 0.0437 - val_acc: 0.4896\n",
      "Epoch 12/30\n",
      "59/59 [==============================] - 0s 658us/sample - loss: 0.0677 - acc: 0.4836 - val_loss: 0.0422 - val_acc: 0.4896\n",
      "Epoch 13/30\n",
      "59/59 [==============================] - 0s 696us/sample - loss: 0.0606 - acc: 0.4841 - val_loss: 0.0407 - val_acc: 0.4896\n",
      "Epoch 14/30\n",
      "59/59 [==============================] - 0s 715us/sample - loss: 0.0575 - acc: 0.4848 - val_loss: 0.0396 - val_acc: 0.4896\n",
      "Epoch 15/30\n",
      "59/59 [==============================] - 0s 660us/sample - loss: 0.0541 - acc: 0.4852 - val_loss: 0.0392 - val_acc: 0.4896\n",
      "Epoch 16/30\n",
      "59/59 [==============================] - 0s 637us/sample - loss: 0.0541 - acc: 0.4849 - val_loss: 0.0391 - val_acc: 0.4896\n",
      "Epoch 17/30\n",
      "59/59 [==============================] - 0s 655us/sample - loss: 0.0520 - acc: 0.4851 - val_loss: 0.0390 - val_acc: 0.4896\n",
      "Epoch 18/30\n",
      "59/59 [==============================] - 0s 674us/sample - loss: 0.0514 - acc: 0.4852 - val_loss: 0.0388 - val_acc: 0.4896\n",
      "Epoch 19/30\n",
      "59/59 [==============================] - 0s 780us/sample - loss: 0.0514 - acc: 0.4853 - val_loss: 0.0385 - val_acc: 0.4896\n",
      "Epoch 20/30\n",
      "59/59 [==============================] - 0s 679us/sample - loss: 0.0510 - acc: 0.4853 - val_loss: 0.0383 - val_acc: 0.4896\n",
      "Epoch 21/30\n",
      "59/59 [==============================] - 0s 728us/sample - loss: 0.0499 - acc: 0.4853 - val_loss: 0.0382 - val_acc: 0.4896\n",
      "Epoch 22/30\n",
      "59/59 [==============================] - 0s 664us/sample - loss: 0.0493 - acc: 0.4853 - val_loss: 0.0381 - val_acc: 0.4896\n",
      "Epoch 23/30\n",
      "59/59 [==============================] - 0s 698us/sample - loss: 0.0495 - acc: 0.4853 - val_loss: 0.0380 - val_acc: 0.4896\n",
      "Epoch 24/30\n",
      "59/59 [==============================] - 0s 647us/sample - loss: 0.0502 - acc: 0.4853 - val_loss: 0.0380 - val_acc: 0.4896\n",
      "Epoch 25/30\n",
      "59/59 [==============================] - 0s 692us/sample - loss: 0.0495 - acc: 0.4853 - val_loss: 0.0379 - val_acc: 0.4896\n",
      "Epoch 26/30\n",
      "59/59 [==============================] - 0s 725us/sample - loss: 0.0488 - acc: 0.4853 - val_loss: 0.0378 - val_acc: 0.4896\n",
      "Epoch 27/30\n",
      "59/59 [==============================] - 0s 743us/sample - loss: 0.0479 - acc: 0.4853 - val_loss: 0.0378 - val_acc: 0.4896\n",
      "Epoch 28/30\n",
      "59/59 [==============================] - 0s 666us/sample - loss: 0.0486 - acc: 0.4853 - val_loss: 0.0377 - val_acc: 0.4896\n",
      "Epoch 29/30\n",
      "59/59 [==============================] - 0s 696us/sample - loss: 0.0482 - acc: 0.4853 - val_loss: 0.0377 - val_acc: 0.4896\n",
      "Epoch 30/30\n",
      "59/59 [==============================] - 0s 645us/sample - loss: 0.0473 - acc: 0.4853 - val_loss: 0.0377 - val_acc: 0.4896\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "# too few data to have a batch_size\n",
    "batch_size = 5\n",
    "num_epoch = 30\n",
    "model_log = cnn_model.fit(train_features, train_labels,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(test_features, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 126us/sample - loss: 0.0417 - acc: 0.4853\n",
      "[0.04170754343523818, 0.4853396]\n"
     ]
    }
   ],
   "source": [
    "score = cnn_model.evaluate(train_features, train_labels, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09066769, 0.12159464, 0.04062372, ..., 0.00159842, 0.00163046,\n",
       "        0.00181997],\n",
       "       [0.07123941, 0.09311324, 0.03540087, ..., 0.00096443, 0.0008665 ,\n",
       "        0.00086579],\n",
       "       [0.08004594, 0.12085637, 0.03253919, ..., 0.00108448, 0.00102615,\n",
       "        0.00115463],\n",
       "       ...,\n",
       "       [0.1292525 , 0.16490254, 0.07589   , ..., 0.00544813, 0.00500983,\n",
       "        0.00518134],\n",
       "       [0.07063195, 0.09879074, 0.03174132, ..., 0.00076237, 0.00064006,\n",
       "        0.00073072],\n",
       "       [0.06935436, 0.09634471, 0.02801588, ..., 0.00060897, 0.00056572,\n",
       "        0.00068578]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.predict(train_features)\n",
    "cnn_test_predicted = cnn_model.predict(test_features)\n",
    "cnn_test_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 230us/sample - loss: 0.0377 - acc: 0.4896\n",
      "[0.03769812732934952, 0.4895725]\n"
     ]
    }
   ],
   "source": [
    "score = cnn_model.evaluate(test_features, test_labels, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>energy</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>...</th>\n",
       "      <th>World Music</th>\n",
       "      <th>genius</th>\n",
       "      <th>noise</th>\n",
       "      <th>saxophone</th>\n",
       "      <th>Favorite Artists</th>\n",
       "      <th>indietronica</th>\n",
       "      <th>feelgood</th>\n",
       "      <th>new</th>\n",
       "      <th>folk-rock</th>\n",
       "      <th>pretty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.663922</td>\n",
       "      <td>0.107875</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.192404</td>\n",
       "      <td>0.779078</td>\n",
       "      <td>0.645608</td>\n",
       "      <td>222076.627451</td>\n",
       "      <td>5.117647</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166732</td>\n",
       "      <td>0.493655</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>0.228118</td>\n",
       "      <td>0.174761</td>\n",
       "      <td>0.686868</td>\n",
       "      <td>0.472711</td>\n",
       "      <td>299176.157895</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.273359</td>\n",
       "      <td>0.671952</td>\n",
       "      <td>0.096359</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.170416</td>\n",
       "      <td>0.690095</td>\n",
       "      <td>0.565460</td>\n",
       "      <td>219076.174603</td>\n",
       "      <td>4.984127</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266913</td>\n",
       "      <td>0.509253</td>\n",
       "      <td>0.066359</td>\n",
       "      <td>0.210820</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>0.624924</td>\n",
       "      <td>0.460534</td>\n",
       "      <td>229373.898990</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.181532</td>\n",
       "      <td>0.582188</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>0.086992</td>\n",
       "      <td>0.169556</td>\n",
       "      <td>0.636631</td>\n",
       "      <td>0.489375</td>\n",
       "      <td>256603.562500</td>\n",
       "      <td>3.187500</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  speechiness  instrumentalness  liveness  \\\n",
       "0      0.085044      0.663922     0.107875          0.000689  0.192404   \n",
       "1      0.166732      0.493655     0.089239          0.228118  0.174761   \n",
       "2      0.273359      0.671952     0.096359          0.000648  0.170416   \n",
       "3      0.266913      0.509253     0.066359          0.210820  0.197497   \n",
       "4      0.181532      0.582188     0.041513          0.086992  0.169556   \n",
       "\n",
       "     energy   valence    duration_ms       key      mode  ...  World Music  \\\n",
       "0  0.779078  0.645608  222076.627451  5.117647  0.705882  ...            0   \n",
       "1  0.686868  0.472711  299176.157895  4.578947  0.552632  ...            0   \n",
       "2  0.690095  0.565460  219076.174603  4.984127  0.507937  ...            0   \n",
       "3  0.624924  0.460534  229373.898990  5.090909  0.707071  ...            0   \n",
       "4  0.636631  0.489375  256603.562500  3.187500  0.812500  ...            0   \n",
       "\n",
       "   genius  noise  saxophone  Favorite Artists  indietronica  feelgood  new  \\\n",
       "0       0      0          0                 0             0         0    0   \n",
       "1       0      0          0                 0             0         0    0   \n",
       "2       0      0          0                 0             0         0    0   \n",
       "3       0      0          0                 0             0         0    0   \n",
       "4       0      0          0                 0             0         0    0   \n",
       "\n",
       "   folk-rock  pretty  \n",
       "0          0       0  \n",
       "1          0       0  \n",
       "2          0       0  \n",
       "3          0       0  \n",
       "4          0       0  \n",
       "\n",
       "[5 rows x 287 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = list(raw_features[0].columns)[4:]\n",
    "#print(feature_names)\n",
    "\n",
    "top_n_tags = 1\n",
    "\n",
    "labels = []\n",
    "with open('labels_100_playlists.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    label_columns = list(data[0].keys())\n",
    "    for item in data:\n",
    "        label = list(item.values())\n",
    "        sorted_label_top_n = sorted(label, reverse=True)[0:top_n_tags]\n",
    "        new_label = [0]*len(label)\n",
    "        for num in sorted_label_top_n:\n",
    "            new_label[label.index(num)] = 1\n",
    "        \n",
    "        labels.append(new_label)\n",
    "        #labels.append(list(item.values()))\n",
    "    \n",
    "features = []\n",
    "for raw_playlist in raw_features:\n",
    "    raw_playlist = raw_playlist.drop(columns=['track_name', 'artist', 'id','Unnamed: 0'])\n",
    "    new_feature_array_playlist = list(raw_playlist.mean())\n",
    "    features.append(new_feature_array_playlist)\n",
    "\n",
    "overall_data = []\n",
    "for i in range(len(features)):\n",
    "    overall_data.append(features[i]+labels[i])\n",
    "\n",
    "overall_df = pd.DataFrame(overall_data, columns = feature_names+label_columns)\n",
    "overall_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#standardize (normalize X_df)\n",
    "X_df = overall_df[feature_names]\n",
    "#X_df=(X_df-X_df.mean())/X_df.std()\n",
    "y_df = overall_df[label_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.85\n",
      "Test accuracy: 0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier(max_depth = 50, min_samples_split = 3, min_samples_leaf = 1,\n",
    "                                   criterion = \"gini\").fit(X_train, y_train)\n",
    "train_tree_acc = tree_model.score(X_train, y_train)\n",
    "test_tree_acc = tree_model.score(X_test, y_test)\n",
    "print(\"Training accuracy:\", train_tree_acc)\n",
    "print(\"Test accuracy:\", test_tree_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_model.predict_proba(np.array([list(X_test.iloc[0])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.5625\n",
      "Test accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest_model = RandomForestClassifier(n_estimators = 100, max_depth = 100, criterion = \"entropy\",\n",
    "                                            min_samples_split = 3, min_samples_leaf = 2,\n",
    "                                            max_features = \"sqrt\").fit(X_train, y_train)\n",
    "train_tree_acc = random_forest_model.score(X_train, y_train)\n",
    "test_tree_acc = random_forest_model.score(X_test, y_test)\n",
    "print(\"Training accuracy:\", train_tree_acc)\n",
    "print(\"Test accuracy:\", test_tree_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest_model.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the probabilities, we can find use k nearest neighbors method to recommend songs for the user with specific playlist. Metric method 1: use the exact predicted probabilities and the normalized weights of the tags of the songs (by dividing 100), compute the mean squared difference. Metric method 2: classifiy the tags into 1 and 0 and compute the distance between the predicted tags and actual tags of the song."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random sampling million songs datasets files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "playlists = []\n",
    "random_indices = np.random.choice([i for i in range(1000)], size = 10)\n",
    "\n",
    "# load data into pandas dataframe\n",
    "for idx in random_indices:\n",
    "    songs_df = pd.read_csv(\"songs/songs{}.csv\".format(idx))\n",
    "\n",
    "    # get playlists into dictionaries and store in a list\n",
    "\n",
    "    id_nums = set(songs_df['pid'].tolist())\n",
    "    songs_df = songs_df.groupby(\"pid\")\n",
    "\n",
    "    for id in id_nums:\n",
    "        playlist = songs_df.get_group(id)\n",
    "        playlists.append(playlist.to_dict())\n",
    "\n",
    "# store the list of dictionaries into json file\n",
    "with open('random_playlists', 'w') as fout:\n",
    "    json.dump(playlists, fout)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in random_playlists json file and randomly sample n playlists from the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import random\n",
    "\n",
    "n = 100\n",
    "with open('random_playlists.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    random_data = random.sample(data, n)\n",
    "    #print(len(random_data))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenate pairs of artists and track names of each track into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplaylists_artist_tracks = []\\nfor playlist in random_data:\\n    artist_names = list(playlist.get(\"artist_name\").values())\\n    track_names = list(playlist.get(\"track_name\").values())\\n    artist_tracks = zip(artist_names, track_names)\\n    playlists_artist_tracks += list(artist_tracks)\\nprint(len(playlists_artist_tracks))\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "playlists_artist_tracks = []\n",
    "for playlist in random_data:\n",
    "    artist_names = list(playlist.get(\"artist_name\").values())\n",
    "    track_names = list(playlist.get(\"track_name\").values())\n",
    "    artist_tracks = zip(artist_names, track_names)\n",
    "    playlists_artist_tracks += list(artist_tracks)\n",
    "print(len(playlists_artist_tracks))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the normalized tag weights of these randomly sampled songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsongs_with_tags = {}\\n\\nfor track in playlists_artist_tracks:\\n    tag_dict = get_zero_dict()\\n    tags_with_weights = get_tags_from_track(track[0], track[1])\\n    if tags_with_weights is not None and len(tags_with_weights) != 0:\\n        for pair in tags_with_weights:\\n            tag_dict.update({pair[0]: pair[1]/100.0})\\n    print(tag_dict)\\n    songs_with_tags.update({(track[0], track[1]): list(tag_dict.values())})\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "songs_with_tags = {}\n",
    "\n",
    "for track in playlists_artist_tracks:\n",
    "    tag_dict = get_zero_dict()\n",
    "    tags_with_weights = get_tags_from_track(track[0], track[1])\n",
    "    if tags_with_weights is not None and len(tags_with_weights) != 0:\n",
    "        for pair in tags_with_weights:\n",
    "            tag_dict.update({pair[0]: pair[1]/100.0})\n",
    "    print(tag_dict)\n",
    "    songs_with_tags.update({(track[0], track[1]): list(tag_dict.values())})\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dump to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncandidates_with_tags = {}\\n\\nfor key_tuple in list(songs_with_tags.keys()):\\n    #turn tuple of artist_track into 'artist_name*,*track_name'\\n    candidates_with_tags.update({str(key_tuple[0])+'*,*'+str(key_tuple[1]): songs_with_tags.get(key_tuple)})\\n\\nwith open('candidates_with_tags', 'w') as fout:\\n    json.dump(candidates_with_tags, fout)\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "candidates_with_tags = {}\n",
    "\n",
    "for key_tuple in list(songs_with_tags.keys()):\n",
    "    #turn tuple of artist_track into 'artist_name*,*track_name'\n",
    "    candidates_with_tags.update({str(key_tuple[0])+'*,*'+str(key_tuple[1]): songs_with_tags.get(key_tuple)})\n",
    "\n",
    "with open('candidates_with_tags', 'w') as fout:\n",
    "    json.dump(candidates_with_tags, fout)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NN Song Recommender (Currently using k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Songs Recommended by ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in json file as dictionary\n",
    "with open('candidates_with_tags.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "songs_with_tags = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT: tags for candidate songs, and the predicted tags of one playlist in the test dataset from a model\n",
    "# OUTPUT: a song recommendation\n",
    "def make_recommendation(candidate_tags, playlist_predicted_tag, random_songs):    \n",
    "    min_distance = float('inf');\n",
    "    rec = -1;\n",
    "    for c in range(len(candidate_tags)):\n",
    "        candidate = list(random_songs.values())[c]\n",
    "        #each_distance = sum((np.array(candidate) - np.array(playlist_predicted_tag)) ** 2)\n",
    "        each_distance = sum((candidate - playlist_predicted_tag) ** 2)\n",
    "        if each_distance < min_distance:\n",
    "            min_distance = each_distance;\n",
    "            rec = c;\n",
    "    return rec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2257, 5271, 3318, 5271, 3901, 2648, 3658, 4568, 236, 4670, 1383, 4119, 924, 888, 3318, 2257, 658, 5344, 1405, 241]\n"
     ]
    }
   ],
   "source": [
    "### Predict by KNN ### \n",
    "candidate_tags = list(songs_with_tags.keys())\n",
    "recommendations = []\n",
    "\n",
    "test_predicted = probs_sigmoid_with_linear\n",
    "\n",
    "#playlists_artist_tracks can be replaced by accessing the dumped json file \"candidates_with_tags\"\n",
    "playlists_artist_tracks = songs_with_tags\n",
    "random_songs = playlists_artist_tracks\n",
    "\n",
    "\n",
    "for each_playlist_predicted_tag in test_predicted:\n",
    "    rec_for_test = make_recommendation(candidate_tags, each_playlist_predicted_tag, random_songs)\n",
    "    recommendations.append(rec_for_test)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jay Sean', 'Do You Remember'), ('Zara Larsson', 'Lush Life'), ('Snoop Dogg', 'Signs'), ('Zara Larsson', 'Lush Life'), ('Coldplay', 'Princess of China'), ('Daryl Hall & John Oates', 'Sara Smile'), ('Bon Iver', 'Skinny Love'), ('Rich Homie Quan', 'Flex (Ooh, Ooh, Ooh)'), ('The Flaming Lips', 'Fight Test'), ('Edwin McCain', \"I'll Be\"), ('Fountains Of Wayne', 'Hackensack'), ('WALK THE MOON', 'Shut Up and Dance'), ('Dave Matthews Band', 'Two Step'), ('Stealers Wheel', 'Stuck In The Middle With You'), ('Snoop Dogg', 'Signs'), ('Jay Sean', 'Do You Remember'), ('Paramore', 'Misguided Ghosts'), ('Beck', 'Wow'), ('David Bowie', 'Starman - 2012 Remastered Version'), ('The Killers', \"All These Things That I've Done\")]\n"
     ]
    }
   ],
   "source": [
    "songs_recommended = [];\n",
    "for rec in recommendations:\n",
    "    rec_track = tuple(candidate_tags[rec].split(\"*,*\"))\n",
    "    songs_recommended.append(rec_track)\n",
    "print(songs_recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Songs Recommended by CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 4567, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "### Predict by KNN ### \n",
    "candidate_tags = list(songs_with_tags.keys())\n",
    "recommendations = []\n",
    "\n",
    "test_predicted = cnn_test_predicted\n",
    "\n",
    "#playlists_artist_tracks can be replaced by accessing the dumped json file \"candidates_with_tags\"\n",
    "playlists_artist_tracks = songs_with_tags\n",
    "random_songs = playlists_artist_tracks\n",
    "\n",
    "for each_playlist_predicted_tag in test_predicted:\n",
    "#     print(each_playlist_predicted_tag)\n",
    "    rec_for_test = make_recommendation(candidate_tags, each_playlist_predicted_tag, random_songs)\n",
    "    recommendations.append(rec_for_test)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Disclosure', 'Omen - Radio Edit'), ('Disclosure', 'Omen - Radio Edit'), ('Disclosure', 'Omen - Radio Edit'), ('Disclosure', 'Omen - Radio Edit'), ('2 LIVE CREW', 'Mega Mixx Iii'), ('Disclosure', 'Omen - Radio Edit'), ('Disclosure', 'Omen - Radio Edit')]\n"
     ]
    }
   ],
   "source": [
    "songs_recommended = [];\n",
    "for rec in recommendations:\n",
    "    rec_track = tuple(candidate_tags[rec].split(\"*,*\"))\n",
    "    songs_recommended.append(rec_track)\n",
    "print(songs_recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future K-NN Model use, we need to write a function to compute the k nearest songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(predicted, song):\n",
    "    return np.sqrt(sum((np.array(predicted) - np.array(song)) ** 2))\n",
    "\n",
    "# return the indices of the k nearest songs\n",
    "def k_nearest_indices(predicted, songs, k):\n",
    "    distances = []\n",
    "    for song in songs:\n",
    "        distances.append(distance(predicted, song))\n",
    "    sorted_distances_top_k = sorted(distances)[0:k]\n",
    "    k_indices = []\n",
    "    for top_ele in sorted_distances_top_k:\n",
    "        k_indices.append(distances.index(top_ele))\n",
    "    return k_indices\n",
    "\n",
    "# return the k nearest songs\n",
    "def k_nearest_songs(predicted, songs_dict, k):\n",
    "    songs = list(songs_dict.values())\n",
    "    k_indices = k_nearest_indices(predicted, songs, k)\n",
    "    k_recommended_songs = [tuple(list(songs_dict.keys())[idx].split(\"*,*\")) for idx in k_indices]\n",
    "    return k_recommended_songs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo for ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in json file as dictionary\n",
    "with open('candidates_with_tags.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "songs_with_tags = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jay Sean', 'Do You Remember'), ('The Black Eyed Peas', 'Boom Boom Pow')]\n",
      "[('Zara Larsson', 'Lush Life'), ('Dua Lipa', 'Hotter Than Hell')]\n",
      "[('Snoop Dogg', 'Signs'), ('The Black Eyed Peas', 'Boom Boom Pow')]\n",
      "[('Zara Larsson', 'Lush Life'), ('Dua Lipa', 'Hotter Than Hell')]\n",
      "[('Coldplay', 'Princess of China'), ('Coldplay', 'Adventure Of A Lifetime')]\n",
      "[('Daryl Hall & John Oates', 'Sara Smile'), ('Daryl Hall & John Oates', 'Rich Girl')]\n",
      "[('Bon Iver', 'Skinny Love'), ('Paramore', 'Misguided Ghosts')]\n",
      "[('Rich Homie Quan', 'Flex (Ooh, Ooh, Ooh)'), ('Beastie Boys', 'Brass Monkey')]\n",
      "[('The Flaming Lips', 'Fight Test'), ('Grouplove', 'Ways To Go')]\n",
      "[('Edwin McCain', \"I'll Be\"), ('Paramore', 'Misguided Ghosts')]\n",
      "[('Fountains Of Wayne', 'Hackensack'), ('The White Stripes', \"We're Going To Be Friends\")]\n",
      "[('WALK THE MOON', 'Shut Up and Dance'), ('Liz Phair', \"Why Can't I?\")]\n",
      "[('Dave Matthews Band', 'Two Step'), ('OneRepublic', \"Let's Hurt Tonight\")]\n",
      "[('Stealers Wheel', 'Stuck In The Middle With You'), ('Blue Swede', 'Hooked on a Feeling')]\n",
      "[('Snoop Dogg', 'Signs'), ('The Black Eyed Peas', 'Boom Boom Pow')]\n",
      "[('Jay Sean', 'Do You Remember'), ('Chris Brown', 'Yeah 3x')]\n",
      "[('Paramore', 'Misguided Ghosts'), ('The White Stripes', \"We're Going To Be Friends\")]\n",
      "[('Beck', 'Wow'), ('Yeah Yeah Yeahs', 'Heads Will Roll')]\n",
      "[('David Bowie', 'Starman - 2012 Remastered Version'), ('Daryl Hall & John Oates', 'Rich Girl')]\n",
      "[('The Killers', \"All These Things That I've Done\"), ('The Killers', 'Read My Mind')]\n"
     ]
    }
   ],
   "source": [
    "songs_dict = songs_with_tags\n",
    "test_predicted = probs_sigmoid_with_linear\n",
    "for predicted in test_predicted:\n",
    "    print(k_nearest_songs(predicted, songs_dict, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jay Sean', 'Do You Remember'), ('The Black Eyed Peas', 'Boom Boom Pow'), ('Timbaland', 'The Way I Are')]\n",
      "[('Zara Larsson', 'Lush Life'), ('Dua Lipa', 'Hotter Than Hell'), ('Marina and the Diamonds', 'How To Be A Heartbreaker')]\n",
      "[('Snoop Dogg', 'Signs'), ('The Black Eyed Peas', 'Boom Boom Pow'), ('Missy Elliott', 'Get Ur Freak On')]\n",
      "[('Zara Larsson', 'Lush Life'), ('Dua Lipa', 'Hotter Than Hell'), ('Twenty One Pilots', 'Heavydirtysoul')]\n",
      "[('Coldplay', 'Princess of China'), ('Coldplay', 'Adventure Of A Lifetime'), ('Panic! At The Disco', 'That Green Gentleman (Things Have Changed)')]\n",
      "[('Daryl Hall & John Oates', 'Sara Smile'), ('Daryl Hall & John Oates', 'Rich Girl'), ('The Jackson 5', 'I Want You Back')]\n",
      "[('Bon Iver', 'Skinny Love'), ('Paramore', 'Misguided Ghosts'), ('Alexi Murdoch', 'Orange Sky')]\n",
      "[('Rich Homie Quan', 'Flex (Ooh, Ooh, Ooh)'), ('Beastie Boys', 'Brass Monkey'), ('N.W.A.', 'Straight Outta Compton')]\n",
      "[('The Flaming Lips', 'Fight Test'), ('Grouplove', 'Ways To Go'), ('Portugal. The Man', 'All Your Light (Times Like These)')]\n",
      "[('Edwin McCain', \"I'll Be\"), ('Paramore', 'Misguided Ghosts'), ('Liz Phair', \"Why Can't I?\")]\n",
      "[('Fountains Of Wayne', 'Hackensack'), ('The White Stripes', \"We're Going To Be Friends\"), ('Liz Phair', \"Why Can't I?\")]\n",
      "[('WALK THE MOON', 'Shut Up and Dance'), ('Liz Phair', \"Why Can't I?\"), ('The Script', 'Breakeven')]\n",
      "[('Dave Matthews Band', 'Two Step'), ('OneRepublic', \"Let's Hurt Tonight\"), ('The Gaslight Anthem', \"The '59 Sound\")]\n",
      "[('Stealers Wheel', 'Stuck In The Middle With You'), ('Blue Swede', 'Hooked on a Feeling'), ('Paul McCartney', 'Live And Let Die')]\n",
      "[('Snoop Dogg', 'Signs'), ('The Black Eyed Peas', 'Boom Boom Pow'), ('Jeremih', 'Down On Me')]\n",
      "[('Jay Sean', 'Do You Remember'), ('Chris Brown', 'Yeah 3x'), ('Rihanna', 'Desperado')]\n",
      "[('Paramore', 'Misguided Ghosts'), ('The White Stripes', \"We're Going To Be Friends\"), ('Bon Iver', 'Skinny Love')]\n",
      "[('Beck', 'Wow'), ('Yeah Yeah Yeahs', 'Heads Will Roll'), ('The Flaming Lips', 'Fight Test')]\n",
      "[('David Bowie', 'Starman - 2012 Remastered Version'), ('Daryl Hall & John Oates', 'Rich Girl'), ('Fleetwood Mac', 'Say You Love Me')]\n",
      "[('The Killers', \"All These Things That I've Done\"), ('The Killers', 'Read My Mind'), ('Pixies', 'Where Is My Mind?')]\n"
     ]
    }
   ],
   "source": [
    "for predicted in test_predicted:\n",
    "    print(k_nearest_songs(predicted, songs_dict, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem of this recommender system is that we are always recommending popular songs and failing to recommend songs of a niche or newly released songs. Since unpopular songs and newly released songs seldom have any tags or top frequent tags on the unique tags list. So we need to consider recommending such songs once in a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
